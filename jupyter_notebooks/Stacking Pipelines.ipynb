{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking Pipelines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+sHoC437UNwVVA8sbugmv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5gbVGPNZWPR"
      },
      "source": [
        "# Import repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsIRBPkQY-vt",
        "outputId": "fa36546b-9c3d-471a-eb04-a1dd5ca6e3b9"
      },
      "source": [
        "!git clone https://github.com/FernandoDoreto/convert-streamlit-to-django.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'convert-streamlit-to-django'...\n",
            "remote: Enumerating objects: 424, done.\u001b[K\n",
            "remote: Counting objects: 100% (424/424), done.\u001b[K\n",
            "remote: Compressing objects: 100% (310/310), done.\u001b[K\n",
            "remote: Total 424 (delta 195), reused 287 (delta 86), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (424/424), 373.74 KiB | 4.56 MiB/s, done.\n",
            "Resolving deltas: 100% (195/195), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v6jSgUoZMkV",
        "outputId": "4042c73d-7265-48e1-b38c-059938a6565b"
      },
      "source": [
        "%cd /content/convert-streamlit-to-django"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/convert-streamlit-to-django\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qEIV0cHtZUUH",
        "outputId": "7b610f50-d1d8-40c8-fd1e-055da0897fb8"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/convert-streamlit-to-django'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpPJS2YmZU2P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFyUM3AUZcye"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cop0CpQuZrKc",
        "outputId": "96f8582a-fa35-4b1a-cb45-25a2a584e7ef"
      },
      "source": [
        "pip install streamlit"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/99/a8913c21bd07a14f72658a01784414ffecb380ddd0f9a127257314fea697/streamlit-0.80.0-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (20.9)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 47.1MB/s \n",
            "\u001b[?25hCollecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.12.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.1)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.1)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Collecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Collecting watchdog; platform_system != \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/ba/a36ca5b4e75649a002f06531862467b3eb5c768caa23d6d88b921fe238d8/watchdog-2.0.2-py3-none-manylinux2014_x86_64.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/bc/f0e44828e4290367c869591d50d3671a4d0ee94926da6cb734b7b200308c/pydeck-0.6.2-py2.py3-none-any.whl (4.2MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2MB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (1.15.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (4.4.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tzlocal->streamlit) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (54.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/7d/9f8ac1b1b76f2f1538b5650f0b5636bae082724b1e06939a3a9d38e1380e/ipykernel-5.5.3-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (22.0.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.4)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp37-none-any.whl size=13448 sha256=1c5ebbe7d25b2732a46ffbe887e5187b721edcd2b80791b50402ffaeaf448131\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built blinker\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: smmap, gitdb, gitpython, validators, blinker, watchdog, base58, ipykernel, pydeck, streamlit\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed base58-2.1.0 blinker-1.4 gitdb-4.0.7 gitpython-3.1.14 ipykernel-5.5.3 pydeck-0.6.2 smmap-4.0.0 streamlit-0.80.0 validators-0.18.2 watchdog-2.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZVRbgK4Ze-f"
      },
      "source": [
        "from src.processing.data_management import LoadIrisDataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jayxAhv3ZuMn"
      },
      "source": [
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTpNrYWrabB8"
      },
      "source": [
        "df = LoadIrisDataset()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipkI6MYmg7TI"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yJr5dNiautq"
      },
      "source": [
        "* Train Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JumJM7znakWR",
        "outputId": "f962a046-e1bf-4245-916a-8dfeb5a3f35f"
      },
      "source": [
        "from app_pages.page_ml_ClfIrisSpecies import ML_ClfIrisSpeciesBody\n",
        "from config import config\n",
        "from src.processing.data_management import TrainTestSplit\n",
        "from src.machine_learning.train_pipeline import TrainPipeline_ClfIrisSpecies\n",
        "import src.machine_learning.pipeline as pipeline"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp5nl2pHaxMy"
      },
      "source": [
        " X_train, X_test,y_train, y_test = TrainTestSplit(df=df,\n",
        "                                                  TARGET=config.ClfIrisSpecies_TARGET)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NM6PH_3bsIK"
      },
      "source": [
        "# Grid Search on 1 pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2QTcEfHbSqf"
      },
      "source": [
        "from config import config\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "\n",
        "\n",
        "ClfIrisSpecies_DT = Pipeline(\n",
        "    [       \n",
        "        (\"feat_selection\",SelectFromModel(DecisionTreeClassifier())),\n",
        "        (\"feat_scaling\",StandardScaler()),\n",
        "        (\"model\", DecisionTreeClassifier())\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "_parameters = {\n",
        "    'model__splitter': [\"best\",\"random\"],\n",
        "    'model__max_depth': [None,3,5,10],\n",
        "    'model__criterion': [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "\n",
        "_pipe = GridSearchCV(\n",
        "\t\testimator = ClfIrisSpecies_DT,\n",
        "\t\tparam_grid = _parameters, \n",
        "\t\tcv = 5,   \n",
        "\t\tn_jobs = -2,\n",
        "\t\tverbose = 2\n",
        "\t\t)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2VbAbZHecnz",
        "outputId": "261ff5c6-2294-406e-b3ed-d6bedd136f32"
      },
      "source": [
        "_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('feat_selection',\n",
              "                                        SelectFromModel(estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                                                         class_weight=None,\n",
              "                                                                                         criterion='gini',\n",
              "                                                                                         max_depth=None,\n",
              "                                                                                         max_features=None,\n",
              "                                                                                         max_leaf_nodes=None,\n",
              "                                                                                         min_impurity_decrease=0.0,\n",
              "                                                                                         min_impurity_split=None,\n",
              "                                                                                         min_samples_leaf=1,\n",
              "                                                                                         min_samples_split=2,\n",
              "                                                                                         min_weight_fraction_...\n",
              "                                                               min_samples_split=2,\n",
              "                                                               min_weight_fraction_leaf=0.0,\n",
              "                                                               presort='deprecated',\n",
              "                                                               random_state=None,\n",
              "                                                               splitter='best'))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'model__criterion': ['gini', 'entropy'],\n",
              "                         'model__max_depth': [None, 3, 5, 10],\n",
              "                         'model__splitter': ['best', 'random']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5GHuutxfpyD",
        "outputId": "103d6699-afb8-4adf-fcd0-64c796cadfe3"
      },
      "source": [
        "_pipe.best_estimator_"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('feat_selection',\n",
              "                 SelectFromModel(estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                                  class_weight=None,\n",
              "                                                                  criterion='gini',\n",
              "                                                                  max_depth=None,\n",
              "                                                                  max_features=None,\n",
              "                                                                  max_leaf_nodes=None,\n",
              "                                                                  min_impurity_decrease=0.0,\n",
              "                                                                  min_impurity_split=None,\n",
              "                                                                  min_samples_leaf=1,\n",
              "                                                                  min_samples_split=2,\n",
              "                                                                  min_weight_fraction_leaf=0.0,\n",
              "                                                                  presort='deprecated',\n",
              "                                                                  random_state=N...\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('model',\n",
              "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                        criterion='gini', max_depth=None,\n",
              "                                        max_features=None, max_leaf_nodes=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        presort='deprecated', random_state=None,\n",
              "                                        splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo88lAxHbwJe"
      },
      "source": [
        "# Grid Search on Stacking pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFnoNBUFbT50"
      },
      "source": [
        "from config import config\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "ClfIrisSpecies_DT = Pipeline(\n",
        "    [       \n",
        "        (\"feat_selection\",SelectFromModel(DecisionTreeClassifier())),\n",
        "        (\"feat_scaling\",StandardScaler()),\n",
        "        (\"model\", DecisionTreeClassifier())\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "_parameters_DT = {\n",
        "    'model__splitter': [\"best\",\"random\"],\n",
        "    'model__max_depth': [None,3,5,10],\n",
        "    'model__criterion': [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "\n",
        "PipelineClfIrisSpecies_DT = GridSearchCV(\n",
        "\t\testimator = ClfIrisSpecies_DT,\n",
        "\t\tparam_grid = _parameters_DT, \n",
        "\t\tcv = 5,   \n",
        "\t\tn_jobs = -2,\n",
        "\t\tverbose = 2\n",
        "\t\t)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DzRWLe8bfeX"
      },
      "source": [
        "ClfIrisSpecies_GB = Pipeline(\n",
        "    [       \n",
        "        (\"feat_selection\",SelectFromModel(GradientBoostingClassifier(random_state=config.RANDOM_STATE))),\n",
        "        (\"feat_scaling\",StandardScaler()),\n",
        "        (\"model\", GradientBoostingClassifier(random_state=config.RANDOM_STATE,learning_rate=0.1))\n",
        "    ]\n",
        ")\n",
        "\n",
        "_parameters_GB = {\n",
        "    'model__learning_rate': [1e-1,1e-2,5e-1],\n",
        "    'model__n_estimators': [100,800]\n",
        "}\n",
        "\n",
        "\n",
        "PipelineClfIrisSpecies_GB = GridSearchCV(\n",
        "\t\testimator = ClfIrisSpecies_GB,\n",
        "\t\tparam_grid = _parameters_GB, \n",
        "\t\tcv = 5,   \n",
        "\t\tn_jobs = -2,\n",
        "\t\tverbose = 2\n",
        "\t\t)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O20QBKEljusR"
      },
      "source": [
        "ClfIrisStacking = StackingClassifier(\n",
        "    classifiers=[\n",
        "        PipelineClfIrisSpecies_GB,\n",
        "        PipelineClfIrisSpecies_DT\n",
        "    ],\n",
        "    use_probas=True,\n",
        "    meta_classifier=LogisticRegression(solver='liblinear')\n",
        ")\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fioy3-mlju3P",
        "outputId": "ba151501-2de5-413a-95e7-ad5b8211a2fd"
      },
      "source": [
        "ClfIrisStacking.fit(X_train,y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=100 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  model__learning_rate=0.1, model__n_estimators=100, total=   0.4s\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=100 ...............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  model__learning_rate=0.1, model__n_estimators=100, total=   0.4s\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=100 ...............\n",
            "[CV]  model__learning_rate=0.1, model__n_estimators=100, total=   0.4s\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=100 ...............\n",
            "[CV]  model__learning_rate=0.1, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=100 ...............\n",
            "[CV]  model__learning_rate=0.1, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.1, model__n_estimators=800, total=   1.4s\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.1, model__n_estimators=800, total=   1.4s\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.1, model__n_estimators=800, total=   1.3s\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.1, model__n_estimators=800, total=   1.3s\n",
            "[CV] model__learning_rate=0.1, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.1, model__n_estimators=800, total=   1.1s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=100 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=100 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=100, total=   0.4s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=100 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=100 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=100 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=800 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=800, total=   1.5s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=800 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=800, total=   1.5s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=800 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=800, total=   1.5s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=800 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=800, total=   1.5s\n",
            "[CV] model__learning_rate=0.01, model__n_estimators=800 ..............\n",
            "[CV]  model__learning_rate=0.01, model__n_estimators=800, total=   1.4s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=100 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=100 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=100 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=100 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=100 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=100, total=   0.3s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=800, total=   1.3s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=800, total=   1.3s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=800, total=   1.3s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=800, total=   1.4s\n",
            "[CV] model__learning_rate=0.5, model__n_estimators=800 ...............\n",
            "[CV]  model__learning_rate=0.5, model__n_estimators=800, total=   1.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-2)]: Done  30 out of  30 | elapsed:   25.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=best .\n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=best \n",
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=best \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=best \n",
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=best \n",
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=best \n",
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=gini, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=gini, model__max_depth=10, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=None, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=None, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=3, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=3, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=5, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=5, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=best \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=best, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=random, total=   0.0s\n",
            "[CV] model__criterion=entropy, model__max_depth=10, model__splitter=random \n",
            "[CV]  model__criterion=entropy, model__max_depth=10, model__splitter=random, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-2)]: Done  80 out of  80 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(average_probas=False,\n",
              "                   classifiers=[GridSearchCV(cv=5, error_score=nan,\n",
              "                                             estimator=Pipeline(memory=None,\n",
              "                                                                steps=[('feat_selection',\n",
              "                                                                        SelectFromModel(estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
              "                                                                                                                             criterion='friedman_mse',\n",
              "                                                                                                                             init=None,\n",
              "                                                                                                                             learning_rate=0.1,\n",
              "                                                                                                                             loss='deviance',\n",
              "                                                                                                                             max_depth=3,\n",
              "                                                                                                                             max_features=None,\n",
              "                                                                                                                             max_leaf_nodes=None,\n",
              "                                                                                                                             min_impurity_decrease...\n",
              "                   meta_classifier=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                      dual=False,\n",
              "                                                      fit_intercept=True,\n",
              "                                                      intercept_scaling=1,\n",
              "                                                      l1_ratio=None,\n",
              "                                                      max_iter=100,\n",
              "                                                      multi_class='auto',\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      random_state=None,\n",
              "                                                      solver='liblinear',\n",
              "                                                      tol=0.0001, verbose=0,\n",
              "                                                      warm_start=False),\n",
              "                   store_train_meta_features=False, use_clones=True,\n",
              "                   use_features_in_secondary=False, use_probas=True, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LSSaElGpy0q",
        "outputId": "ce69791f-28dc-4fea-d9b1-818a6e47c089",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ClfIrisStacking.predict_proba(X_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9352621 , 0.03260976, 0.03212814],\n",
              "       [0.03224065, 0.93560376, 0.03215559],\n",
              "       [0.9352621 , 0.03260976, 0.03212814],\n",
              "       [0.03222091, 0.03727086, 0.93050823],\n",
              "       [0.9352621 , 0.03260976, 0.03212814],\n",
              "       [0.03224065, 0.93560376, 0.03215559],\n",
              "       [0.03222075, 0.03721328, 0.93056597],\n",
              "       [0.9352621 , 0.03260976, 0.03212814],\n",
              "       [0.9352621 , 0.03260976, 0.03212814],\n",
              "       [0.03224065, 0.93560376, 0.03215559],\n",
              "       [0.03222075, 0.03721328, 0.93056597],\n",
              "       [0.03224065, 0.93560376, 0.03215559],\n",
              "       [0.03224162, 0.93560219, 0.03215618],\n",
              "       [0.03222075, 0.03721328, 0.93056597],\n",
              "       [0.03224065, 0.93560376, 0.03215559],\n",
              "       [0.03222066, 0.03721328, 0.93056606],\n",
              "       [0.03222095, 0.03721925, 0.9305598 ],\n",
              "       [0.03224065, 0.93560376, 0.03215559],\n",
              "       [0.0322408 , 0.93560352, 0.03215568],\n",
              "       [0.9352621 , 0.03260976, 0.03212814],\n",
              "       [0.9352621 , 0.03260976, 0.03212814],\n",
              "       [0.03222244, 0.03726239, 0.93051517],\n",
              "       [0.03222072, 0.03721355, 0.93056574],\n",
              "       [0.03226291, 0.93553792, 0.03219917],\n",
              "       [0.9352621 , 0.03260976, 0.03212814],\n",
              "       [0.03224162, 0.93560219, 0.03215618],\n",
              "       [0.03224065, 0.93560376, 0.03215559],\n",
              "       [0.03222075, 0.03721328, 0.93056597],\n",
              "       [0.9352621 , 0.03260976, 0.03212814],\n",
              "       [0.9352621 , 0.03260976, 0.03212814]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFP9nqQXqT1e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}